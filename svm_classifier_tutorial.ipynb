{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManikGo/ML/blob/main/svm_classifier_tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lecture 7 Project\n",
        "# SVM Classifier \n",
        "\n",
        "Coodinator: Sajal Khandelwal"
      ],
      "metadata": {
        "id": "YqyQ5AzvSRtk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCXFmefqVzRP"
      },
      "source": [
        "# **Support Vector Machines Classifier** \n",
        "\n",
        "Hello friends,\n",
        "\n",
        "Support Vector Machines (SVMs in short) are supervised machine learning algorithms that are used for classification and regression purposes. In this kernel, we are going to build a Support Vector Machines classifier to classify a Pulsar star. The dataset used for this project is **Predicting a Pulsar Star**. \n",
        "\n",
        "So, let's get started."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E8OzGWacVzRU"
      },
      "source": [
        "#  Dataset description<a class=\"anchor\" id=\"5\"></a>\n",
        "\n",
        "\n",
        "\n",
        "I have used the **Predicting a Pulsar Star** dataset for this project.\n",
        "\n",
        "Pulsars are a rare type of Neutron star that produce radio emission detectable here on Earth. They are of considerable scientific interest as probes of space-time, the inter-stellar medium, and states of matter. Classification algorithms in particular are being adopted, which treat the data sets as binary classification problems. Here the legitimate pulsar examples form  minority positive class and spurious examples form the majority negative class.\n",
        "\n",
        "The data set shared here contains 16,259 spurious examples caused by RFI/noise, and 1,639 real pulsar examples. Each row lists the variables first, and the class label is the final entry. The class labels used are 0 (negative) and 1 (positive).\n",
        "\n",
        "\n",
        "### Attribute Information:\n",
        "\n",
        "\n",
        "Each candidate is described by 8 continuous variables, and a single class variable. The first four are simple statistics obtained from the integrated pulse profile. The remaining four variables are similarly obtained from the DM-SNR curve . These are summarised below:\n",
        "\n",
        "1. Mean of the integrated profile.\n",
        "\n",
        "2. Standard deviation of the integrated profile.\n",
        "\n",
        "3. Excess kurtosis of the integrated profile.\n",
        "\n",
        "4. Skewness of the integrated profile.\n",
        "\n",
        "5. Mean of the DM-SNR curve.\n",
        "\n",
        "6. Standard deviation of the DM-SNR curve.\n",
        "\n",
        "7. Excess kurtosis of the DM-SNR curve.\n",
        "\n",
        "8. Skewness of the DM-SNR curve.\n",
        "\n",
        "9. Class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF8HwxYfVzRW"
      },
      "source": [
        "# **Import libraries** <a class=\"anchor\" id=\"6\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Cw-KMHBpVzRW"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import matplotlib.pyplot as plt # for data visualization\n",
        "import seaborn as sns # for statistical data visualization\n",
        "\n",
        "\n",
        "# # Input data files are available in the \"../input/\" directory.\n",
        "# # For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "# import os\n",
        "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "#     for filename in filenames:\n",
        "#         print(os.path.join(dirname, filename))\n",
        "\n",
        "# # Any results you write to the current directory are saved as output.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IV1IuNuVVzRY"
      },
      "source": [
        "# **Import dataset** <a class=\"anchor\" id=\"7\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "cE8ynLpnVzRY",
        "outputId": "16c7bddf-f1c4-417d-eb74-24431af1361b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-1e1b50aff336>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'pulsar_stars.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    480\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    481\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 482\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    809\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 811\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    812\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1038\u001b[0m             )\n\u001b[1;32m   1039\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers/base_parser.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mmemory_map\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0mstorage_options\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m             \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"encoding_errors\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"strict\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m         )\n\u001b[1;32m    231\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    705\u001b[0m                 \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                 \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                 \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    708\u001b[0m             )\n\u001b[1;32m    709\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'pulsar_stars.csv'"
          ]
        }
      ],
      "source": [
        "data = 'pulsar_stars.csv'\n",
        "\n",
        "df = pd.read_csv(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhttS4DYVzRZ"
      },
      "source": [
        "# **Exploratory data analysis** <a class=\"anchor\" id=\"8\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S-pGJWXaVzRZ",
        "outputId": "45863723-383d-41f7-9b45-7ad0daad1244",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-12451ec8415d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# view dimensions of dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# view dimensions of dataset\n",
        "\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3c5I7DsVzRa"
      },
      "source": [
        "We can see that there are 17898 instances and 9 variables in the data set."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "scrolled": true,
        "id": "thtLz9iXVzRb",
        "outputId": "fa42e950-f1ab-4834-d05b-350c3f72641c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 200
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-268f15947c8b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# let's preview the dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
          ]
        }
      ],
      "source": [
        "# let's preview the dataset\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FnHB5P8VzRb"
      },
      "source": [
        "We can see that there are 9 variables in the dataset. 8 are continuous variables and 1 is discrete variable. The discrete variable is `target_class` variable. It is also the target variable.\n",
        "\n",
        "\n",
        "Now, I will view the column names to check for leading and trailing spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9Dy5cqqVzRc"
      },
      "outputs": [],
      "source": [
        "# view the column names of the dataframe\n",
        "\n",
        "col_names = df.columns\n",
        "\n",
        "col_names"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6qeVQ2lVzRc"
      },
      "source": [
        "We can see that there are leading spaces (spaces at the start of the string name) in the dataframe. So, I will remove these leading spaces."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWVur9UcVzRc"
      },
      "outputs": [],
      "source": [
        "# remove leading spaces from column names\n",
        "\n",
        "df.columns = df.columns.str.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "idJjEK1xVzRd"
      },
      "source": [
        "I have removed the leading spaces from the column names. Let's again view the column names to confirm the same."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JadJlM_pVzRd"
      },
      "outputs": [],
      "source": [
        "# view column names again\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "COzp4k6jVzRd"
      },
      "source": [
        "We can see that the leading spaces are removed from the column name. But the column names are very long. So, I will make them short by renaming them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1Qrk7DyVzRd"
      },
      "outputs": [],
      "source": [
        "# rename column names\n",
        "\n",
        "df.columns = ['IP Mean', 'IP Sd', 'IP Kurtosis', 'IP Skewness', \n",
        "              'DM-SNR Mean', 'DM-SNR Sd', 'DM-SNR Kurtosis', 'DM-SNR Skewness', 'target_class']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6veeTdBGVzRd"
      },
      "outputs": [],
      "source": [
        "# view the renamed column names\n",
        "\n",
        "df.columns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-deGsseVzRe"
      },
      "source": [
        "We can see that the column names are shortened. IP stands for `integrated profile` and DM-SNR stands for `delta modulation and signal to noise ratio`. Now, it is much more easy to work with the columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de9Ai_plVzRe"
      },
      "source": [
        "Our target variable is the `target_class` column. So, I will check its distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MrDWeC51VzRe"
      },
      "outputs": [],
      "source": [
        "# check distribution of target_class column\n",
        "\n",
        "df['target_class'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vt5NdI-GVzRe"
      },
      "outputs": [],
      "source": [
        "# view the percentage distribution of target_class column\n",
        "\n",
        "df['target_class'].value_counts()/np.float(len(df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mE_OokUuVzRe"
      },
      "source": [
        "We can see that percentage of observations of the class label `0` and `1` is 90.84% and 9.16%. So, this is a class imbalanced problem. I will deal with that in later section."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fhxu150VzRe"
      },
      "outputs": [],
      "source": [
        "# view summary of dataset\n",
        "\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5EOjnD14VzRf"
      },
      "source": [
        "We can see that there are no missing values in the dataset and all the variables are numerical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0BQHl8cVzRf"
      },
      "source": [
        "### Explore missing values in variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tz8yV3CKVzRf"
      },
      "outputs": [],
      "source": [
        "# check for missing values in variables\n",
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXuUjeqxVzRf"
      },
      "source": [
        "We can see that there are no missing values in the dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYrQ8y8HVzRf"
      },
      "source": [
        "### Outliers in numerical variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS--XX4WVzRf"
      },
      "outputs": [],
      "source": [
        "# view summary statistics in numerical variables\n",
        "\n",
        "round(df.describe(),2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tl5hgaWPVzRf"
      },
      "source": [
        "On closer inspection, we can suspect that all the continuous variables may contain outliers.\n",
        "\n",
        "\n",
        "I will draw boxplots to visualise outliers in the above variables. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIh_uJ4JVzRg"
      },
      "outputs": [],
      "source": [
        "# draw boxplots to visualize outliers\n",
        "\n",
        "plt.figure(figsize=(24,20))\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "fig = df.boxplot(column='IP Mean')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Mean')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "fig = df.boxplot(column='IP Sd')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Sd')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "fig = df.boxplot(column='IP Kurtosis')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Kurtosis')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "fig = df.boxplot(column='IP Skewness')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('IP Skewness')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "fig = df.boxplot(column='DM-SNR Mean')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Mean')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "fig = df.boxplot(column='DM-SNR Sd')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Sd')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "fig = df.boxplot(column='DM-SNR Kurtosis')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Kurtosis')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "fig = df.boxplot(column='DM-SNR Skewness')\n",
        "fig.set_title('')\n",
        "fig.set_ylabel('DM-SNR Skewness')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfN5e9pZVzRg"
      },
      "source": [
        "The above boxplots confirm that there are lot of outliers in these variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czGeqkA6VzRg"
      },
      "source": [
        "### Handle outliers with SVMs\n",
        "\n",
        "\n",
        "There are 2 variants of SVMs. They are `hard-margin variant of SVM` and `soft-margin variant of SVM`.\n",
        "\n",
        "\n",
        "The `hard-margin variant of SVM` does not deal with outliers. In this case, we want to find the hyperplane with maximum margin such that every training point is correctly classified with margin at least 1. This technique does not handle outliers well.\n",
        "\n",
        "\n",
        "Another version of SVM is called `soft-margin variant of SVM`. In this case, we can have a few points incorrectly classified or \n",
        "classified with a margin less than 1. But for every such point, we have to pay a penalty in the form of `C` parameter, which controls the outliers. `Low C` implies we are allowing more outliers and `high C` implies less outliers.\n",
        "\n",
        "\n",
        "The message is that since the dataset contains outliers, so the value of C should be high while training the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NAYEs1koVzRg"
      },
      "source": [
        "### Check the distribution of variables\n",
        "\n",
        "\n",
        "Now, I will plot the histograms to check distributions to find out if they are normal or skewed. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gx7vhptZVzRg"
      },
      "outputs": [],
      "source": [
        "# plot histogram to check distribution\n",
        "\n",
        "\n",
        "plt.figure(figsize=(24,20))\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 1)\n",
        "fig = df['IP Mean'].hist(bins=20)\n",
        "fig.set_xlabel('IP Mean')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 2)\n",
        "fig = df['IP Sd'].hist(bins=20)\n",
        "fig.set_xlabel('IP Sd')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 3)\n",
        "fig = df['IP Kurtosis'].hist(bins=20)\n",
        "fig.set_xlabel('IP Kurtosis')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 4)\n",
        "fig = df['IP Skewness'].hist(bins=20)\n",
        "fig.set_xlabel('IP Skewness')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 5)\n",
        "fig = df['DM-SNR Mean'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Mean')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 6)\n",
        "fig = df['DM-SNR Sd'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Sd')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 7)\n",
        "fig = df['DM-SNR Kurtosis'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Kurtosis')\n",
        "fig.set_ylabel('Number of pulsar stars')\n",
        "\n",
        "\n",
        "plt.subplot(4, 2, 8)\n",
        "fig = df['DM-SNR Skewness'].hist(bins=20)\n",
        "fig.set_xlabel('DM-SNR Skewness')\n",
        "fig.set_ylabel('Number of pulsar stars')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hl4aho1tVzRh"
      },
      "source": [
        "We can see that all the 8 continuous variables are skewed. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XjLyLX1eVzRh"
      },
      "source": [
        "# **Declare feature vector and target variable** <a class=\"anchor\" id=\"9\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VbOJYqURVzRh"
      },
      "outputs": [],
      "source": [
        "X = df.drop(['target_class'], axis=1)\n",
        "\n",
        "y = df['target_class']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3JY6yZsVzRh"
      },
      "source": [
        "# **Split data into separate training and test set** <a class=\"anchor\" id=\"10\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xb2KrlxNVzRh"
      },
      "outputs": [],
      "source": [
        "# split X and y into training and testing sets\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FqThvr54VzRh"
      },
      "outputs": [],
      "source": [
        "# check the shape of X_train and X_test\n",
        "\n",
        "X_train.shape, X_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VT94tITmVzRh"
      },
      "source": [
        "# **Feature Scaling** <a class=\"anchor\" id=\"11\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at1Nm2hTVzRh"
      },
      "outputs": [],
      "source": [
        "cols = X_train.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blP2XPOyVzRh"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "\n",
        "X_test = scaler.transform(X_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QTqhpvZ9VzRi"
      },
      "outputs": [],
      "source": [
        "X_train = pd.DataFrame(X_train, columns=[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHVe2Nr2VzRi"
      },
      "outputs": [],
      "source": [
        "X_test = pd.DataFrame(X_test, columns=[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VC0_X67iVzRi"
      },
      "outputs": [],
      "source": [
        "X_train.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9C7jHTbPVzRi"
      },
      "source": [
        "We now have `X_train` dataset ready to be fed into the Logistic Regression classifier. I will do it as follows."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9lEFseZVzRi"
      },
      "source": [
        "# **Run SVM with default hyperparameters** <a class=\"anchor\" id=\"12\"></a>\n",
        "\n",
        "\n",
        "Default hyperparameter means C=1.0,  kernel=`rbf` and gamma=`auto` among other parameters."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xsVEJuG4VzRi"
      },
      "outputs": [],
      "source": [
        "# import SVC classifier\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "# import metrics to compute accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# instantiate classifier with default hyperparameters\n",
        "svc=SVC() \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with default hyperparameters: {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4iYROWRsVzRi"
      },
      "source": [
        "### Run SVM with rbf kernel and C=100.0\n",
        "\n",
        "\n",
        "We have seen that there are outliers in our dataset. So, we should increase the value of C as higher C means fewer outliers. \n",
        "So, I will run SVM with kernel=`rbf` and C=100.0."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qCrz3H-NVzRi"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with rbf kernel and C=100\n",
        "svc=SVC(C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-lRBzyCVzRj"
      },
      "source": [
        "We can see that we obtain a higher accuracy with C=100.0 as higher C means less outliers.\n",
        "\n",
        "Now, I will further increase the value of C=1000.0 and check accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "61ODZoO8VzRj"
      },
      "source": [
        "### Run SVM with rbf kernel and C=1000.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nsgFlsNhVzRj"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with rbf kernel and C=1000\n",
        "svc=SVC(C=1000.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with rbf kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Afr_FZRAVzRj"
      },
      "source": [
        "In this case, we can see that the accuracy had decreased with C=1000.0"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A73_eHu9VzRj"
      },
      "source": [
        "# **Run SVM with linear kernel** <a class=\"anchor\" id=\"13\"></a>\n",
        "\n",
        "\n",
        "\n",
        "### Run SVM with linear kernel and C=1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "54ZCfo78VzRj"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with linear kernel and C=1.0\n",
        "linear_svc=SVC(kernel='linear', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred_test=linear_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred_test)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxERZacBVzRj"
      },
      "source": [
        "### Run SVM with linear kernel and C=100.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2m5AElfpVzRk"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with linear kernel and C=100.0\n",
        "linear_svc100=SVC(kernel='linear', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xz97rTjeVzRk"
      },
      "source": [
        "### Run SVM with linear kernel and C=1000.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xMk7mjQzVzRk"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with linear kernel and C=1000.0\n",
        "linear_svc1000=SVC(kernel='linear', C=1000.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "linear_svc1000.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=linear_svc1000.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with linear kernel and C=1000.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GqBOjPk5VzRk"
      },
      "source": [
        "We can see that we can obtain higher accuracy with C=100.0 and C=1000.0 as compared to C=1.0."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0lSfan5vVzRk"
      },
      "source": [
        "Here, **y_test** are the true class labels and **y_pred** are the predicted class labels in the test-set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDoYqxzWVzRk"
      },
      "source": [
        "### Compare the train-set and test-set accuracy\n",
        "\n",
        "\n",
        "Now, I will compare the train-set and test-set accuracy to check for overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UDH4E8flVzRk"
      },
      "outputs": [],
      "source": [
        "y_pred_train = linear_svc.predict(X_train)\n",
        "\n",
        "y_pred_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dh5zugwVVzRl"
      },
      "outputs": [],
      "source": [
        "print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qjCpexCcVzRl"
      },
      "source": [
        "We can see that the training set and test-set accuracy are very much comparable."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uVmGsb8xVzRl"
      },
      "source": [
        "### Check for overfitting and underfitting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odTpv7WxVzRl"
      },
      "outputs": [],
      "source": [
        "# print the scores on training and test set\n",
        "\n",
        "print('Training set score: {:.4f}'.format(linear_svc.score(X_train, y_train)))\n",
        "\n",
        "print('Test set score: {:.4f}'.format(linear_svc.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HTd2CzuVVzRl"
      },
      "source": [
        "The training-set accuracy score is 0.9783 while the test-set accuracy to be 0.9830. These two values are quite comparable. So, there is no question of overfitting. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_Y41A0fVzRl"
      },
      "source": [
        "### Compare model accuracy with null accuracy\n",
        "\n",
        "\n",
        "So, the model accuracy is 0.9832. But, we cannot say that our model is very good based on the above accuracy. We must compare it with the **null accuracy**. Null accuracy is the accuracy that could be achieved by always predicting the most frequent class.\n",
        "\n",
        "So, we should first check the class distribution in the test set. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tMD67A0fVzRl"
      },
      "outputs": [],
      "source": [
        "# check class distribution in test set\n",
        "\n",
        "y_test.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1D2fVBsVzRl"
      },
      "source": [
        "We can see that the occurences of most frequent class `0` is 3306. So, we can calculate null accuracy by dividing 3306 by total number of occurences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QUYLhdrCVzRl"
      },
      "outputs": [],
      "source": [
        "# check null accuracy score\n",
        "\n",
        "null_accuracy = (3306/(3306+274))\n",
        "\n",
        "print('Null accuracy score: {0:0.4f}'. format(null_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TTyb5D5VzRl"
      },
      "source": [
        "We can see that our model accuracy score is 0.9830 but null accuracy score is 0.9235. So, we can conclude that our SVM classifier is doing a very good job in predicting the class labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SEpwhJ_OVzRm"
      },
      "source": [
        "# **Run SVM with polynomial kernel** <a class=\"anchor\" id=\"14\"></a>\n",
        "\n",
        "\n",
        "### Run SVM with polynomial kernel and C=1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1SRNjmZdVzRm"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with polynomial kernel and C=1.0\n",
        "poly_svc=SVC(kernel='poly', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHnioBzvVzRm"
      },
      "source": [
        " ### Run SVM with polynomial kernel and C=100.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKvJ0G0mVzRm"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with polynomial kernel and C=100.0\n",
        "poly_svc100=SVC(kernel='poly', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "poly_svc100.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=poly_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with polynomial kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqfdvaH1VzRm"
      },
      "source": [
        "Polynomial kernel gives poor performance. It may be overfitting the training set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9lp9WTLVzRn"
      },
      "source": [
        "# **Run SVM with sigmoid kernel** <a class=\"anchor\" id=\"15\"></a>\n",
        "\n",
        "\n",
        "### Run SVM with sigmoid kernel and C=1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Su-j-dnVzRn"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with sigmoid kernel and C=1.0\n",
        "sigmoid_svc=SVC(kernel='sigmoid', C=1.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=1.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LsM8E42LVzRn"
      },
      "source": [
        "### Run SVM with sigmoid kernel and C=100.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tGjVAmtAVzRn"
      },
      "outputs": [],
      "source": [
        "# instantiate classifier with sigmoid kernel and C=100.0\n",
        "sigmoid_svc100=SVC(kernel='sigmoid', C=100.0) \n",
        "\n",
        "\n",
        "# fit classifier to training set\n",
        "sigmoid_svc100.fit(X_train,y_train)\n",
        "\n",
        "\n",
        "# make predictions on test set\n",
        "y_pred=sigmoid_svc100.predict(X_test)\n",
        "\n",
        "\n",
        "# compute and print accuracy score\n",
        "print('Model accuracy score with sigmoid kernel and C=100.0 : {0:0.4f}'. format(accuracy_score(y_test, y_pred)))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qVEbNTL7VzRn"
      },
      "source": [
        "We can see that sigmoid kernel is also performing poorly just like with polynomial kernel."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kqr5Dv_qVzRn"
      },
      "source": [
        "### Comments\n",
        "\n",
        "\n",
        "We get maximum accuracy with `rbf` and `linear` kernel with C=100.0. and the accuracy is 0.9832. Based on the above analysis we can conclude that our classification model accuracy is very good. Our model is doing a very good job in terms of predicting the class labels.\n",
        "\n",
        "\n",
        "But, this is not true. Here, we have an imbalanced dataset. The problem is that accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem.\n",
        "\n",
        "\n",
        "So, we must explore alternative metrices that provide better guidance in selecting models. In particular, we would like to know the underlying distribution of values and the type of errors our classifer is making. \n",
        "\n",
        "\n",
        "One such metric to analyze the model performance in imbalanced classes problem is `Confusion matrix`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HiZLfAvGVzRo"
      },
      "source": [
        "# **Confusion matrix** <a class=\"anchor\" id=\"16\"></a>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6knUPl5lVzRo"
      },
      "outputs": [],
      "source": [
        "# Print the Confusion Matrix and slice it into four pieces\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cm = confusion_matrix(y_test, y_pred_test)\n",
        "\n",
        "print('Confusion matrix\\n\\n', cm)\n",
        "\n",
        "print('\\nTrue Positives(TP) = ', cm[0,0])\n",
        "\n",
        "print('\\nTrue Negatives(TN) = ', cm[1,1])\n",
        "\n",
        "print('\\nFalse Positives(FP) = ', cm[0,1])\n",
        "\n",
        "print('\\nFalse Negatives(FN) = ', cm[1,0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OyvV0rHwVzRo"
      },
      "outputs": [],
      "source": [
        "# visualize confusion matrix with seaborn heatmap\n",
        "\n",
        "cm_matrix = pd.DataFrame(data=cm, columns=['Actual Positive:1', 'Actual Negative:0'], \n",
        "                                 index=['Predict Positive:1', 'Predict Negative:0'])\n",
        "\n",
        "sns.heatmap(cm_matrix, annot=True, fmt='d', cmap='YlGnBu')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozQdMqakVzRo"
      },
      "source": [
        "# **Classification metrices** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZLmr4gzVzRo"
      },
      "source": [
        "### Classification Report\n",
        "\n",
        "\n",
        "**Classification report** is another way to evaluate the classification model performance. It displays the  **precision**, **recall**, **f1** and **support** scores for the model. I have described these terms in later.\n",
        "\n",
        "We can print a classification report as follows:-"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "317MbFiSVzRp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "erfBsYXlVzRp"
      },
      "source": [
        "### Classification accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JFM3PAQgSD45"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P9YaymdWVzRp"
      },
      "outputs": [],
      "source": [
        "TP = cm[0,0]\n",
        "TN = cm[1,1]\n",
        "FP = cm[0,1]\n",
        "FN = cm[1,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T-_xKYKDVzRp"
      },
      "outputs": [],
      "source": [
        "# print classification accuracy\n",
        "\n",
        "classification_accuracy = (TP + TN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification accuracy : {0:0.4f}'.format(classification_accuracy))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbBfUXt8VzRp"
      },
      "source": [
        "### Classification error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x92-r8isVzRp"
      },
      "outputs": [],
      "source": [
        "# print classification error\n",
        "\n",
        "classification_error = (FP + FN) / float(TP + TN + FP + FN)\n",
        "\n",
        "print('Classification error : {0:0.4f}'.format(classification_error))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuNPKjirVzRq"
      },
      "source": [
        "### Precision\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "otOcLBsdVzRq"
      },
      "outputs": [],
      "source": [
        "# print precision score\n",
        "\n",
        "precision = TP / float(TP + FP)\n",
        "\n",
        "\n",
        "print('Precision : {0:0.4f}'.format(precision))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QuIUjKatVzRt"
      },
      "source": [
        "### Recall\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiX2IaGqVzRt"
      },
      "outputs": [],
      "source": [
        "recall = TP / float(TP + FN)\n",
        "\n",
        "print('Recall or Sensitivity : {0:0.4f}'.format(recall))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwom3iJ3VzRt"
      },
      "source": [
        "### True Positive Rate\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h0j6VfWiVzRt"
      },
      "outputs": [],
      "source": [
        "true_positive_rate = TP / float(TP + FN)\n",
        "\n",
        "\n",
        "print('True Positive Rate : {0:0.4f}'.format(true_positive_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GwbMZQr0VzRt"
      },
      "source": [
        "### False Positive Rate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hMCZ-AAqVzRu"
      },
      "outputs": [],
      "source": [
        "false_positive_rate = FP / float(FP + TN)\n",
        "\n",
        "\n",
        "print('False Positive Rate : {0:0.4f}'.format(false_positive_rate))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2kql-K4lVzRu"
      },
      "source": [
        "### Specificity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "USwUdHDbVzRu"
      },
      "outputs": [],
      "source": [
        "specificity = TN / (TN + FP)\n",
        "\n",
        "print('Specificity : {0:0.4f}'.format(specificity))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3TUOJVfVzRu"
      },
      "source": [
        "# **Results and conclusion** \n",
        "\n",
        "\n",
        "\n",
        "1. There are outliers in our dataset. So, as we increase the value of C to limit fewer outliers, the accuracy increased. This is true with different kinds of kernels.\n",
        "\n",
        "2.\tWe get maximum accuracy with `rbf` and `linear` kernel with C=100.0 and the accuracy is 0.9832. So, we can conclude that our model is doing a very good job in terms of predicting the class labels. But, this is not true. Here, we have an imbalanced dataset. Accuracy is an inadequate measure for quantifying predictive performance in the imbalanced dataset problem. So, we must explore `confusion matrix` that provide better guidance in selecting models. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_9LmOItVzRu"
      },
      "source": [
        "# **References** \n",
        "\n",
        "The work done in this project is inspired from following books and websites:-\n",
        "\n",
        "  1. Hands on Machine Learning with Scikit-Learn and Tensorflow by Aurelien Geron\n",
        "\n",
        "  5. https://en.wikipedia.org/wiki/Support-vector_machine\n",
        "\n",
        "  6. https://www.datacamp.com/community/tutorials/svm-classification-scikit-learn-python\n",
        "\n",
        "  7. http://dataaspirant.com/2017/01/13/support-vector-machine-algorithm/\n",
        "\n",
        "  8. https://www.ritchieng.com/machine-learning-evaluate-classification-model/\n",
        "\n",
        "  9. https://en.wikipedia.org/wiki/Kernel_method\n",
        "\n",
        "  10. https://en.wikipedia.org/wiki/Polynomial_kernel\n",
        "\n",
        "  11. https://en.wikipedia.org/wiki/Radial_basis_function_kernel\n",
        "\n",
        "  12. https://data-flair.training/blogs/svm-kernel-functions/"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "svm-classifier-tutorial.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}